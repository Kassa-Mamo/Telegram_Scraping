{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punkt tokenizer is installed correctly.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Check if the resource exists\n",
    "nltk.data.find('tokenizers/punkt')\n",
    "print(\"Punkt tokenizer is installed correctly.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\user\\Desktop\\10 Acedamy W5\\TELEGRAM_SCRAPPER\\venv\\Scripts\\python.exe\n",
      "Python version: 3.11.6 (tags/v3.11.6:8b6ee5b, Oct  2 2023, 14:57:12) [MSC v.1935 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from telethon import TelegramClient\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, filename=\"scraper.log\", filemode=\"w\",\n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Configurations\n",
    "DATA_FOLDER = r\"C:\\Users\\user\\Desktop\\10 Acedamy W5\\All Data\"\n",
    "CHANNELS_FILE = os.path.join(DATA_FOLDER, \"channels_to_crawl.csv\")\n",
    "SCRAPED_FILE = os.path.join(DATA_FOLDER, \"scraped_data.csv\")\n",
    "API_ID = 20173022  # Replace with your API ID\n",
    "API_HASH = 'bab4a3351ed7634a8c1a3f8767fcf75c'  # Replace with your API Hash\n",
    "\n",
    "\n",
    "def load_channels(file_path):\n",
    "    \"\"\"Load channel usernames from a CSV file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            # Ensure each line is a list of strings, then we can access the correct column (1 index) and strip\n",
    "            return [line[1].strip() for line in csv.reader(f) if len(line) > 1]\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Channels file not found at {file_path}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "async def scrape_channel(client, channel, writer):\n",
    "    \"\"\"Scrape messages from a Telegram channel.\"\"\"\n",
    "    try:\n",
    "        async for message in client.iter_messages(channel, limit=100):\n",
    "            writer.writerow([channel, message.sender_id, message.date, message.text])\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error scraping channel {channel}: {e}\")\n",
    "\n",
    "\n",
    "async def scrape_telegram_data():\n",
    "    \"\"\"Main function to scrape Telegram data.\"\"\"\n",
    "    logging.info(\"Starting Telegram scraper...\")\n",
    "    channels = load_channels(CHANNELS_FILE)\n",
    "    if not channels:\n",
    "        logging.error(\"No channels to scrape.\")\n",
    "        return\n",
    "\n",
    "    async with TelegramClient('scraper', API_ID, API_HASH) as client:\n",
    "        with open(SCRAPED_FILE, 'w', newline='', encoding='utf-8') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(['channel', 'sender', 'timestamp', 'message'])\n",
    "            for channel in channels:\n",
    "                logging.info(f\"Scraping channel: {channel}\")\n",
    "                await scrape_channel(client, channel, writer)\n",
    "\n",
    "    logging.info(\"Scraping completed.\")\n",
    "\n",
    "\n",
    "# Use await for environments with an active event loop\n",
    "if __name__ == \"__main__\":\n",
    "    await scrape_telegram_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled data saved in CoNLL format to labeled_data.conll\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the entity types for labeling\n",
    "ENTITY_TYPES = {\n",
    "    \"B-Product\": \"Product entity\",\n",
    "    \"I-Product\": \"Product entity continuation\",\n",
    "    \"B-LOC\": \"Location entity\",\n",
    "    \"I-LOC\": \"Location entity continuation\",\n",
    "    \"B-PRICE\": \"Price entity\",\n",
    "    \"I-PRICE\": \"Price entity continuation\",\n",
    "    \"O\": \"Other (no entity)\"\n",
    "}\n",
    "\n",
    "# Example dataset (replace this with your dataset)\n",
    "data = [\n",
    "    (\"Baby bottle እንግዲኛ አሁን ዋጋ 1000 ብር\", \"B-Product I-Product O B-PRICE I-PRICE O\"),\n",
    "    (\"Addis Abeba በፍቅር እንቆቅልሽ\", \"B-LOC I-LOC O B-Product I-Product\")\n",
    "]\n",
    "\n",
    "# Convert the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Message\", \"Label\"])\n",
    "\n",
    "# Function to save labeled data in CoNLL format\n",
    "def save_conll_format(df, file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            message = row['Message']\n",
    "            labels = row['Label'].split()\n",
    "            message_tokens = message.split()\n",
    "\n",
    "            # Iterate over tokens and corresponding labels\n",
    "            for token, label in zip(message_tokens, labels):\n",
    "                f.write(f\"{token} {label}\\n\")\n",
    "            \n",
    "            f.write(\"\\n\")  # Blank line between sentences/messages\n",
    "\n",
    "    print(f\"Labeled data saved in CoNLL format to {file_path}\")\n",
    "\n",
    "# Save the labeled data to CoNLL format\n",
    "save_conll_format(df, \"labeled_data.conll\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
